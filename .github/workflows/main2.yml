name: Weekly News Scraper & Claude Analysis

on:
  schedule:
    - cron: '0 6 * * 0'   # Sundays at 06:00 UTC
  workflow_dispatch:

jobs:
  scrape-and-analyze:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # --- Fast sanity checks so failures are obvious ---
      - name: Verify repo files exist
        run: |
          ls -la
          test -f combined_scraper.py
          test -f analyze_with_claude_single.py
          test -f send_analysis_email_Version2.py

      - name: Verify required secrets are present (not printing values)
        shell: bash
        run: |
          for v in CLAUDE_API_KEY SMTP_SERVER SMTP_PORT EMAIL_USER EMAIL_PASSWORD EMAIL_TO; do
            if [ -z "${!v}" ]; then
              echo "::error::Missing secret $v"; exit 1
            else
              echo "Found secret $v"
            fi
          done
        env:
          CLAUDE_API_KEY: ${{ secrets.CLAUDE_API_KEY }}
          SMTP_SERVER: ${{ secrets.SMTP_SERVER }}
          SMTP_PORT: ${{ secrets.SMTP_PORT }}
          EMAIL_USER: ${{ secrets.EMAIL_USER }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
          EMAIL_TO: ${{ secrets.EMAIL_TO }}

      # 1) Scrape static (non-RC) sites into a single JSON
      - name: Scrape all non-Radio-Canada sites
        run: |
          python combined_scraper.py --exclude-rc
          echo "---- scraped_data ----"; ls -la scraped_data || true

      # 2) Analyze with Claude (single pass)
      - name: Analyze scraped news with Claude
        env:
          CLAUDE_API_KEY: ${{ secrets.CLAUDE_API_KEY }}
        run: |
          # patch deprecated model id if still present (no-op otherwise)
          sed -i "s/claude-3-5-sonnet-20241022/claude-sonnet-4-20250514/g" analyze_with_claude_single.py || true
          python analyze_with_claude_single.py
          echo "---- analysis ----"; ls -la analysis || true
          echo "---- head of latest analysis (for debugging) ----"
          LATEST=$(ls -t analysis/claude_analysis_*.txt 2>/dev/null | head -n 1 || true)
          if [ -n "$LATEST" ]; then head -n 40 "$LATEST"; fi

      # 3) Normalize filename so your mailer can find it
      - name: Prepare analysis file for email script
        id: prep
        shell: bash
        run: |
          set -e
          mkdir -p scraped_data
          LATEST=$(ls -t analysis/claude_analysis_*.txt 2>/dev/null | head -n 1 || true)
          if [ -z "$LATEST" ]; then
            echo "::error::No analysis file found in analysis/"; exit 1
          fi
          OUT="scraped_data/$(date +%Y%m%d)_claude_analysis.txt"
          cp "$LATEST" "$OUT"
          echo "prepared=$OUT" >> "$GITHUB_OUTPUT"
          ls -la scraped_data

      # 4) Email latest analysis results (your existing script)
      - name: Email latest analysis results
        env:
          SMTP_SERVER: ${{ secrets.SMTP_SERVER }}
          SMTP_PORT: ${{ secrets.SMTP_PORT }}
          EMAIL_USER: ${{ secrets.EMAIL_USER }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
          EMAIL_TO: ${{ secrets.EMAIL_TO }}
        run: |
          python send_analysis_email_Version2.py

      # 5) Upload artifacts (even if email fails)
      - name: Upload results as workflow artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: news-analysis-results
          path: |
            scraped_data/news_articles_*.json
            analysis/*.txt
            scraped_data/*_claude_analysis.txt
          if-no-files-found: warn
